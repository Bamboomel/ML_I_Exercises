{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WhpMgiS1o5A"
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "The goal of this lab is to introduce you to data preprocessing techniques in order to make your data suitable for applying a learning algorithm.\n",
    "\n",
    "## 1. Handling Missing Values\n",
    "\n",
    "A common (and very unfortunate) data property is the ocurrence of missing and erroneous values in multiple features in datasets. For this exercise we will be using a data set about abalone snails.\n",
    "The data set is contained in the Zip file you downloaded from Moodle (abalone.csv).\n",
    "\n",
    "To determine the age of a abalone snail you have to kill the snail and count the annual\n",
    "rings. You are told to estimate the age of a snail on the basis of the following attributes:\n",
    "1. type: male (0), female (1) and infant (2)\n",
    "2. length in mm\n",
    "3. width in mm\n",
    "4. height in mm\n",
    "5. total weight in grams\n",
    "6. weight of the meat in grams\n",
    "7. drained weight in grams\n",
    "8. weight of the shell in grams\n",
    "9. number of annual rings (number of rings +1, 5 yields age)\n",
    "\n",
    "However, the data is incomplete. Missing values are marked with −1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aTRoZnye1o5D",
    "outputId": "3b2669b0-1ea1-46d6-b768-638722442986",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
       "0     0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
       "1     1   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
       "2     0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
       "3     2  -1.000  0.255   0.080        0.2050       0.0895          0.0395   \n",
       "4     2   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
       "\n",
       "   shell_weight  num_rings  \n",
       "0         0.070         -1  \n",
       "1         0.210          9  \n",
       "2         0.155         10  \n",
       "3         0.055          7  \n",
       "4         0.120          8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load data \n",
    "df = pd.read_csv(\"http://www.cs.uni-potsdam.de/ml/teaching/ss15/ida/uebung02/abalone.csv\") #Should this not work please use the csv that was part of the zip file.\n",
    "df.columns=['type','length','width','height','total_weight','meat_weight','drained_weight','shell_weight','num_rings']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
       "0   0.0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
       "1   1.0   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
       "2   0.0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
       "3   2.0     NaN  0.255   0.080        0.2050       0.0895          0.0395   \n",
       "4   2.0   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
       "\n",
       "   shell_weight  num_rings  \n",
       "0         0.070        NaN  \n",
       "1         0.210        9.0  \n",
       "2         0.155       10.0  \n",
       "3         0.055        7.0  \n",
       "4         0.120        8.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# df_nan = df.drop(columns='type')\n",
    "df_nan = df.replace(-1,np.NaN)\n",
    "df_nan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_KMa47j1o5E"
   },
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "Compute the mean of of each numeric column and the counts of each categorical column, excluding the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-dCq2-NW1o5F"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "      <td>3271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.955671</td>\n",
       "      <td>0.523445</td>\n",
       "      <td>0.407424</td>\n",
       "      <td>0.139467</td>\n",
       "      <td>0.826354</td>\n",
       "      <td>0.358718</td>\n",
       "      <td>0.179689</td>\n",
       "      <td>0.238330</td>\n",
       "      <td>9.925099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.833652</td>\n",
       "      <td>0.120243</td>\n",
       "      <td>0.099358</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>0.487932</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.108907</td>\n",
       "      <td>0.139079</td>\n",
       "      <td>3.227777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>0.251750</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.351000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type       length        width       height  total_weight  \\\n",
       "count  3271.000000  3271.000000  3271.000000  3271.000000   3271.000000   \n",
       "mean      0.955671     0.523445     0.407424     0.139467      0.826354   \n",
       "std       0.833652     0.120243     0.099358     0.042613      0.487932   \n",
       "min       0.000000     0.075000     0.055000     0.000000      0.002000   \n",
       "25%       0.000000     0.450000     0.350000     0.115000      0.440500   \n",
       "50%       1.000000     0.545000     0.425000     0.140000      0.802500   \n",
       "75%       2.000000     0.615000     0.480000     0.165000      1.145000   \n",
       "max       2.000000     0.815000     0.650000     1.130000      2.825500   \n",
       "\n",
       "       meat_weight  drained_weight  shell_weight    num_rings  \n",
       "count  3271.000000     3271.000000   3271.000000  3271.000000  \n",
       "mean      0.358718        0.179689      0.238330     9.925099  \n",
       "std       0.220866        0.108907      0.139079     3.227777  \n",
       "min       0.001000        0.000500      0.001500     1.000000  \n",
       "25%       0.186000        0.092500      0.130000     8.000000  \n",
       "50%       0.338500        0.171000      0.235000     9.000000  \n",
       "75%       0.500500        0.251750      0.325000    11.000000  \n",
       "max       1.351000        0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop = df_nan.dropna(axis=0)\n",
    "df_drop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I0CjV2c1o5G"
   },
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "Compute the median of each numeric column,  excluding the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sw_28SAt1o5G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length            0.5450\n",
       "width             0.4250\n",
       "height            0.1400\n",
       "total_weight      0.8025\n",
       "meat_weight       0.3385\n",
       "drained_weight    0.1710\n",
       "shell_weight      0.2350\n",
       "num_rings         9.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.iloc[:,1:].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMltOlp_1o5G"
   },
   "source": [
    "### Exercise 1.3\n",
    "\n",
    "Handle the missing values in a way that you find suitable. Think about different ways. Discuss dis-/advantages of your approach. Argue your choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gxDCHrb31o5G"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>9.921756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.523692</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type    length  width  height  total_weight  meat_weight  drained_weight  \\\n",
       "0   0.0  0.350000  0.265   0.090        0.2255       0.0995          0.0485   \n",
       "1   1.0  0.530000  0.420   0.135        0.6770       0.2565          0.1415   \n",
       "2   0.0  0.440000  0.365   0.125        0.5160       0.2155          0.1140   \n",
       "3   2.0  0.523692  0.255   0.080        0.2050       0.0895          0.0395   \n",
       "4   2.0  0.425000  0.300   0.095        0.3515       0.1410          0.0775   \n",
       "\n",
       "   shell_weight  num_rings  \n",
       "0         0.070   9.921756  \n",
       "1         0.210   9.000000  \n",
       "2         0.155  10.000000  \n",
       "3         0.055   7.000000  \n",
       "4         0.120   8.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean = df_nan.fillna(df_nan.mean())\n",
    "df_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpklBouL1o5H"
   },
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "Perform Z-score normalization on every column (except the type of course!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HbkY--hk1o5I"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.465927</td>\n",
       "      <td>-1.461399</td>\n",
       "      <td>-1.207063</td>\n",
       "      <td>-1.248081</td>\n",
       "      <td>-1.184826</td>\n",
       "      <td>-1.221122</td>\n",
       "      <td>-1.226923</td>\n",
       "      <td>-5.570299e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.123130</td>\n",
       "      <td>-0.112168</td>\n",
       "      <td>-0.314104</td>\n",
       "      <td>-0.468720</td>\n",
       "      <td>-0.359144</td>\n",
       "      <td>-0.208153</td>\n",
       "      <td>-2.890442e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.706344</td>\n",
       "      <td>-0.439122</td>\n",
       "      <td>-0.355478</td>\n",
       "      <td>-0.647150</td>\n",
       "      <td>-0.655729</td>\n",
       "      <td>-0.614030</td>\n",
       "      <td>-0.608384</td>\n",
       "      <td>2.453569e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.563627</td>\n",
       "      <td>-1.450374</td>\n",
       "      <td>-1.290487</td>\n",
       "      <td>-1.230438</td>\n",
       "      <td>-1.304539</td>\n",
       "      <td>-1.336077</td>\n",
       "      <td>-9.162041e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.832941</td>\n",
       "      <td>-1.103602</td>\n",
       "      <td>-1.085408</td>\n",
       "      <td>-0.987436</td>\n",
       "      <td>-0.995537</td>\n",
       "      <td>-0.952333</td>\n",
       "      <td>-0.863076</td>\n",
       "      <td>-6.026242e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type    length     width    height  total_weight  meat_weight  \\\n",
       "0   0.0 -1.465927 -1.461399 -1.207063     -1.248081    -1.184826   \n",
       "1   1.0  0.053238  0.123130 -0.112168     -0.314104    -0.468720   \n",
       "2   0.0 -0.706344 -0.439122 -0.355478     -0.647150    -0.655729   \n",
       "3   2.0  0.000000 -1.563627 -1.450374     -1.290487    -1.230438   \n",
       "4   2.0 -0.832941 -1.103602 -1.085408     -0.987436    -0.995537   \n",
       "\n",
       "   drained_weight  shell_weight     num_rings  \n",
       "0       -1.221122     -1.226923 -5.570299e-16  \n",
       "1       -0.359144     -0.208153 -2.890442e-01  \n",
       "2       -0.614030     -0.608384  2.453569e-02  \n",
       "3       -1.304539     -1.336077 -9.162041e-01  \n",
       "4       -0.952333     -0.863076 -6.026242e-01  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = list(df_mean.columns)\n",
    "numeric_columns.remove('type')\n",
    "\n",
    "# with pandas\n",
    "df_z = df_mean.copy()\n",
    "df_z[numeric_columns] = (df_z[numeric_columns] - df_z[numeric_columns].mean()) / df_z[numeric_columns].std() # .iloc[:,1:] excluding type\n",
    "df_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m df_normalised \u001b[38;5;241m=\u001b[39m df_mean\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 5\u001b[0m df_normalised[numeric_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf_normalised\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_columns\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_normalised = df_mean.copy\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_normalised[numeric_columns] = scaler.fit_transform(df_normalised[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krOpdi_i1o5J"
   },
   "source": [
    "## 2. Preprocessing text (Optional)\n",
    "\n",
    "One possible way to transform text documents into vectors of numeric attributes is to use the TF-IDF representation. We will experiment with this representation using the 20 Newsgroup data set. The data set contains postings on 20 different topics. The classification problem is to decide which of the topics a posting falls into. Here, we will only consider postings about medicine and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "TmhZ8_FC1o5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of each category is: [(0, 'sci.med'), (1, 'sci.space')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['sci.med', 'sci.space']\n",
    "raw_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "print(f'The index of each category is: {[(i,target) for i,target in enumerate(raw_data.target_names)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kWdpZz61o5K"
   },
   "source": [
    "Check out some of the postings, might find some funny ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CFZgvye31o5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sci.med email.\n",
      "\n",
      "There are 1187 emails.\n",
      "\n",
      "From: cfaks@ux1.cts.eiu.edu (Alice Sanders)\n",
      "Subject: Frozen shoulder and lawn mowing\n",
      "Organization: Eastern Illinois University\n",
      "Lines: 12\n",
      "\n",
      "Ihave had a frozen shoulder for over a year or about a year.  It is still\n",
      "partially frozen, and I am still in physical therapy every week.  But the\n",
      "pain has subsided almost completely.  UNTIL last week when I mowed the\n",
      "lawn for twenty minutes each, two days in a row.  I have a push type power\n",
      "mower.  The pain started back up a little bit for the first time in quite\n",
      "a while, and I used ice and medicine again.  Can anybody explain why this\n",
      "particular activity, which does not seem to stress me very much generally,\n",
      "should cause this shoulder problem?\n",
      "\n",
      "Thanks.\n",
      "\n",
      "Alice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.random.randint(0, len(raw_data.data))\n",
    "print (f'This is a {raw_data.target_names[raw_data.target[idx]]} email.\\n')\n",
    "print (f'There are {len(raw_data.data)} emails.\\n')\n",
    "print(raw_data.data[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytNRgBtD1o5L"
   },
   "source": [
    "Lets pick the first 10 postings from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7XjYd0ML1o5L"
   },
   "outputs": [],
   "source": [
    "idxs_med = np.flatnonzero(raw_data.target == 0)\n",
    "idxs_space = np.flatnonzero(raw_data.target == 1)\n",
    "idxs = np.concatenate([idxs_med[:10],idxs_space[:10]])\n",
    "data = np.array(raw_data.data)\n",
    "data = data[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY4YffVy1o5M"
   },
   "source": [
    "<a href=\"http://www.nltk.org/\">NLTK</a> is a toolkit for natural language processing. Take some time to install it and go through this <a href=\"http://www.slideshare.net/japerk/nltk-in-20-minutes\">short tutorial/presentation</a>. (or use e.g. Google colab where the package is prepared already)\n",
    "\n",
    "The downloaded package below is a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GhpnijnB1o5M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/melissathephasdin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in data]\n",
    "vocabulary_size = 1000\n",
    "unknown_token = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LvKCOBjx1o5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1636 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print (f\"Found {len(word_freq.items())} unique words tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yw_h_8Vo1o5N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 1000.\n",
      "The least frequent word in our vocabulary is 'AN' and appeared 1 times.\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    " \n",
    "print (f\"Using vocabulary size {vocabulary_size}.\" )\n",
    "print (f\"The least frequent word in our vocabulary is '{vocab[-1][0]}' and appeared {vocab[-1][1]} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['From: geb@cs.pitt.edu (Gordon Banks)\\nSubject: Re: Striato Nigral Degeneration\\nReply-To: geb@cs.pitt.edu (Gordon Banks)\\nOrganization: Univ. of Pittsburgh Computer Science\\nLines: 16\\n\\nIn article <9303252134.AA09923@walrus.mvhs.edu> ktodd@walrus.mvhs.edu ((Ken Todd)) writes:\\n>I would like any information available on this rare disease.  I understand\\n>that an operation referred to as POLLIDOTOMY may be in order.  Does anyone\\n>know of a physician that performs this procedure.  All responses will be\\n>appreciated.  Please respond via email to ktodd@walrus.mvhs.edu\\n\\nIt isn\\'t that rare, actually.  Many cases that are called Parkinson\\'s\\nDisease turn out on autopsy to be SND.  It should be suspected in any\\ncase of Parkinsonism without tremor and which does not respond to\\nL-dopa therapy.  I don\\'t believe pallidotomy will do much for SND.\\n\\n-- \\n----------------------------------------------------------------------------\\nGordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\\ngeb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \\n----------------------------------------------------------------------------\\n',\n",
       "       \"From: ab961@Freenet.carleton.ca (Robert Allison)\\nSubject: Frequent nosebleeds\\nReply-To: ab961@Freenet.carleton.ca (Robert Allison)\\nOrganization: The National Capital Freenet\\nLines: 18\\n\\n\\nI have between 15 and 25 nosebleeds each week, as a result of a genetic\\npredisposition to weak capillary walls (Osler-Weber-Rendu). Fortunately,\\neach nosebleed is of short duration.\\n\\nDoes anyone know of any method to reduce this frequency? My younger brothers\\neach tried a skin transplant (thigh to nose lining), but their nosebleeds\\nsoon returned. I've seen a reference to an herb called Rutin that is\\nsupposed to help, and I'd like to hear of experiences with it, or other\\ntechniques.\\n-- \\nRobert Allison\\nOttawa, Ontario CANADA\\n\",\n",
       "       'From: rind@enterprise.bih.harvard.edu (David Rind)\\nSubject: Re: erythromycin\\nOrganization: Beth Israel Hospital, Harvard Medical School, Boston Mass., USA\\nLines: 11\\nNNTP-Posting-Host: enterprise.bih.harvard.edu\\n\\nIn article <47974@sdcc12.ucsd.edu> wsun@jeeves.ucsd.edu (Fiberman) writes:\\n>Is erythromycin effective in treating pneumonia?\\n\\nIt depends on the cause of the pneumonia.  For treating bacterial\\npneumonia in young otherwise-healthy non-smokers, erythromycin\\nis usually considered the antibiotic of choice, since it covers\\nthe two most-common pathogens: strep pneumoniae and mycoplasma\\npneumoniae.\\n-- \\nDavid Rind\\nrind@enterprise.bih.harvard.edu\\n',\n",
       "       \"From: uabdpo.dpo.uab.edu!gila005 (Stephen Holland)\\nSubject: Re: diet for Crohn's (IBD)\\nOrganization: Gastroenterology - Univ. of Alabama\\nDistribution: usa\\nLines: 81\\n\\nSummary of thread:\\nA person has Crohns, raw vegetables cause problems (unspecified)\\nSteve Holland replies:  patient may have mild obstruction.  Avoid things\\nthat would plug her up.  Crohn's has no dietary restriction in general.\\n\\nIn article <1993Apr22.210631.13300@aio.jsc.nasa.gov>,\\nspenser@fudd.jsc.nasa.gov (S. Spenser Aden) wrote:\\n> \\n> Interesting statements, simply because I have been told otherwise.  I'm\\n> certainly not questioning Steve's claims, as for one I am not a doctor, and I\\n> agree that foods don't bring on the recurrence of Crohn's.  But inflammation\\n> can be either mildly or DRASTICALLY enhanced due to food.\\n\\nThe feeling obout this has changed in the GI community.  The current\\nfeeling\\nis that inflammation is not induced by food.  There is even evidence that\\npatients deprived of food have mucosal atrophy due to lack of stimulation\\nof\\nintestinal growth factors.  There is now interest in providing small\\namounts\\nof nasogastric feeding to patients on IV nutrition.  But I digress.  \\nSymptoms can be drastically enhanced by food, but not inflammation.\\n\\n> Having had one major obstruction resulting in resection (is that a good enough\\n> caveat :-), I was told that a *LOW RESIDUE* diet is called for.  Basically,\\n> the idea is that if there is inflammation of the gut (which may not be\\n> realized by the patient), any residue in the system can be caught in the folds\\n> of inflammation and constantly irritate, thus exacerbating the problem.\\n> Therefore, anything that doesn't digest completely by the point of common\\n> inflammation should be avoided.  With what I've been told is typical Crohn's,\\n> of the terminal ileum, my diet should be low residue, consisting of:\\n>\\n> Completely out - never again - items:\\n> \\to corn (kernel husk doesn't digest ... most of us know this :-)\\n> \\to popcorn (same)\\n> \\to dried (dehydrated) fruit and fruit skins\\n> \\to nuts (Very tough when it comes to giving up some fudge :-)\\n\\nThe low residue diet is appropriate for you if you still have obstructions.\\nAgain, it is not felt that food causes inflammation.  These foods are\\navoided because they may get stuck.  I'd go ahead and have the\\nfudge, though ;-)  .\\n\\n> Discouraged greatly:\\n> \\to raw vegetables (too fibrous)\\n> \\to wheat and raw grain breads\\n> \\to exotic lettuce (iceberg is ok since it's apparently mostly water)\\n> \\to greens (turnip, mustard, kale, etc...)\\n> \\to little seeds, like sesame (try getting an Arby's without it!)\\n> \\to long grain and wild rice (husky)\\n> \\to beans (you'll generate enough gas alone without them!)\\n> \\to BASICALLY anything that requires heavy digestive processing\\n> \\n> I was told that the more processed the food the better! (rather ironic in this\\n> day and age).  The whole point is PREVENTATIVE ... you want to give your\\n> system as little chance to inflame as possible.  I was told that among the\\n> NUMEROUS things that were heavily discouraged (I only listed a few), to try\\n> the ones I wanted and see how I felt.  If it's bad, don't do it again!\\n> Remember though that this was while I was in remission.  For Veggies: cook the\\n> daylights out of them.  I prefer steaming ... I think it's cooks more\\n> thoroughly - you're mileage may vary.\\n> \\n> As with anything else, CHECK WITH YOUR DOCTOR.  Don't just take my word.  But\\n> this is the info I've been given, and it may be a starting point for\\n> discussion.  Good luck!\\n> \\nSpencer makes an especially good point in having an observant and\\ninformed patient.  Would that many patients be able to tell what\\ncauses them problems.  The digestive processing idea is changing, but\\nif a food causes problems, avoid them.  Be sure that the foods are \\ntested a second time to be sure the food is a real cause.  Crohn's\\ncommonly causes intermittent symptoms and some patients end up with\\nseverly restricted diets that take months to renormalize.\\n\\nThere was a good article in the CCFA newsletter recently that discussed\\nthe issue of dietary restriction of fiber.  It would be worth reading\\nto anyone with an interest in Crohn's.\\n\\nAnd, as I always say when dealing with Crohn's, as does Spencer, Good Luck!\\n\\nSteve Holland\\n\",\n",
       "       'From: dyer@spdcc.com (Steve Dyer)\\nSubject: Re: food-related seizures?\\nOrganization: S.P. Dyer Computer Consulting, Cambridge MA\\nLines: 18\\n\\nIn article <79727@cup.portal.com> mmm@cup.portal.com (Mark Robert Thorson) writes:\\n>I remember hearing a few years back about a new therapy for hyperactivity\\n>which involved aggressively eliminating artificial coloring and flavoring\\n>from the diet.  The theory -- which was backed up by interesting anecdotal\\n>results -- is that certain people are just way more sensitive to these\\n>chemicals than other people.  I don\\'t remember any connection being made\\n>with seizures, but it certainly couldn\\'t hurt to try an all-natural diet.\\n\\nYeah, the \"Feingold Diet\" is a load of crap.  Children diagnosed with ADD\\nwho are placed on this diet show no improvement in their intellectual and\\nsocial skills, which in fact continue to decline.  Of course, the parents\\nwho are enthusiastic about this approach lap it up at the expense of their\\nchildren\\'s development.  So much for the value of \"interesting anecdotal\\nresults\".  People will believe anything if they want to.\\n\\n-- \\nSteve Dyer\\ndyer@ursa-major.spdcc.com aka {ima,harvard,rayssd,linus,m2c}!spdcc!dyer\\n',\n",
       "       'From: Mark-Tarbell@suite.com\\nSubject: Amniocentesis, et. al.\\nOrganization: Suite Software\\nLines: 7\\nReply-To: suite!tarbell@uunet.uu.net\\nNNTP-Posting-Host: gilgamesh.suite.com\\n\\nIs there some difference between the purposes behind\\namniocentesis and chorionic villi sampling? They sound\\nsimilar to me, but are intended to detect different\\nthings?\\n\\nThanks.\\n\\x03\\n',\n",
       "       \"From: mmatusev@radford.vak12ed.edu (Melissa N. Matusevich)\\nSubject: Re: HELP ME INJECT...\\nOrganization: Virginia's Public Education Network (Radford)\\nLines: 5\\n\\nAccording to a previous poster, one should seek a doctor's\\nassistance for injections. But what about Sumatriptin [sp?]?\\nDoesn't one have to inject oneself immediately upon the onset\\nof a migraine?\\n\\n\",\n",
       "       'From: hbloom@moose.uvm.edu (*Heather*)\\nSubject: re: what are the problems with nutrasweet (aspartame)\\nOrganization: University of Vermont -- Division of EMBA Computer Facility\\nLines: 21\\n\\nNutrasweet is a synthetic sweetener a couple thousand times sweeter than\\nsugar.  Some people are concerned about the chemicals that the  body produces \\nwhen it degrades nutrasweet.  It is thought to form formaldehyde and known to\\nfor methanol in the degredation pathway that the body uses to eliminate \\nsubstances.  The real issue is whether the levels of methanol and formaldehyde\\nproduced are high enough to cause significant damage, as both are toxic to\\nliving cells.  All I can say is that I will not consume it.  \\n\\nPhenylalanine is\\nnothing for you to worry about.  It is an amino acid, and everyone uses small\\nquantities of it for protein synthesis in the body.  Some people have a disease\\nknown as phenylketoneurea, and they are missing the enzyme necessary to \\ndegrade this compound and eliminate it from the body.  For them, it will \\naccumulate in the body, and in high levels this is toxic to growing nerve\\ncells.  Therefore, it is Only a major problem in young children (until around\\nage 10 or so) or women who are pregnant and have this disorder.  It used to\\nbe a leading cause of brain damage in infants, but now it can be easily \\ndetected at birth, and then one must simply avoid comsumption of phenylalanine\\nas a child, or when pregnant.  \\n\\n-heather\\n',\n",
       "       \"From: lundby@rtsg.mot.com (Walter F. Lundby)\\nSubject: Re: Is MSG sensitivity superstition?\\nNntp-Posting-Host: accord2\\nOrganization: Motorola Inc., Cellular Infrastructure Group\\nLines: 48\\n\\n\\n>>Is there such a thing as MSG (monosodium glutamate) sensitivity?\\n>>Superstition. Anybody here have experience to the contrary?\\n>>\\n \\nAs a person who is very sensitive to msg and whose wife and kids are\\ntoo, I WANT TO KNOW WHY THE FOOD INDUSTRY WANTS TO PUT MSG IN FOOD!!!\\n\\nSomebody in the industry GIVE ME SOME REASONS WHY!  \\n\\nIS IT AN INDUSTRIAL BYPRODUCT THAT NEEDS GETTING GET RID OF?\\n\\nIS IT TO COVER UP THE FACT THAT THE RECIPES ARE NOT VERY GOOD OR THE FOOD IS POOR QUALITY?\\n\\nDO SOME OF YOU GET A SADISTIC PLEASURE OUT OF MAKING SOME OF US SICK?\\n\\nDO THE TASTE TESTERS HAVE SOME DEFECT IN THEIR FLAVOR SENSORS (MOUTH etc...)\\n  THAT MSG CORRECTS?\\n\\nI REALLY DON'T UNDERSTAND!!!\\n\\nALSO ... Nitrosiamines (sp) and sulfites...   Why them?  There are\\n safer ways to preserve food, wines, and beers!\\n\\nI think \\n1) outlaw the use of these substances without warning labels as\\nlarge as those on cig. packages.\\n2) Require 30% of comparable products on the market to be free of these\\nsubstances and state that they are free of MSG, DYES, NITROSIAMINES and SULFITES on the package.\\n3) While at it outlaw yellow dye #5.  For that matter why dye food?  \\n4) Take the dyes and flavorings out of vitamins.  (In my OSCO only Stress\\nTabs (tm) didn't have yellow dye #5)  { My doctor says Yellow Dye #5 is\\nresponsible for 1/2 of all nasal polyps !!! }\\n\\nKEEP FOOD FOOD!  QUIT PUTTING IN JUNK!\\n\\nJUST MY TWO CENTS WORTH.\\n\\nSig:  A person tired of getting sick from this junk!\\n\\n-- \\nWalter Lundby\\n\\n\\n\\n-- \\nWalter Lundby\\n\\n\",\n",
       "       \"From: dougb@comm.mot.com (Doug Bank)\\nSubject: Do we need a Radiologist to read an Ultrasound?\\nReply-To: dougb@ecs.comm.mot.com\\nOrganization: Motorola Land Mobile Products Sector\\nNntp-Posting-Host: 145.1.146.35\\nLines: 28\\n\\nMy wife's ob-gyn has an ultrasound machine in her office.  When\\nthe doctor couldn't hear a fetal heartbeat (13 weeks) she used\\nthe ultrasound to see if everything was ok.  (it was)\\n\\nOn her next visit, my wife asked another doctor in the office if\\nthey read the ultrasounds themselves or if they had a radiologist\\nread the pictures.  The doctor very vehemently insisted that they\\nwere qualified to read the ultrasound and radiologists were NOT!\\n\\nMy wife is concerned about this.  She saw a TV show a couple months\\nback (something like 20/20 or Dateline NBC, etc.) where an expert\\non fetal ultrasounds (a radiologist) was showing all the different\\ndeffects that could be detected using the ultrasound.\\n\\nShould my wife be concerned?  Should we take the pictures to a \\nradiologist for a second opinion? (and if so, where would we find\\nsuch an expert in Chicago?)  We don't really have any special medical\\nreason to be concerned, but if a radiologist will be able to see\\nthings the ob-gyn can't, then I don't see why we shouldn't use one.\\n\\nAny thoughts?\\n\\n\\n-- \\nDoug Bank                       Private Systems Division\\ndougb@ecs.comm.mot.com          Motorola Communications Sector\\ndougb@nwu.edu                   Schaumburg, Illinois\\ndougb@casbah.acns.nwu.edu       708-576-8207                    \\n\",\n",
       "       'From: flb@flb.optiplan.fi (\"F.Baube[tm]\")\\nSubject: Vandalizing the sky\\nX-Added: Forwarded by Space Digest\\nOrganization: [via International Space University]\\nOriginal-Sender: isu@VACATION.VENARI.CS.CMU.EDU\\nDistribution: sci\\nLines: 12\\n\\nFrom: \"Phil G. Fraering\" <pgf@srl03.cacs.usl.edu>\\n> \\n> Finally: this isn\\'t the Bronze Age, [..]\\n> please try to remember that there are more human activities than\\n> those practiced by the Warrior Caste, the Farming Caste, and the\\n> Priesthood.\\n\\nRight, the Profiting Caste is blessed by God, and may \\n freely blare its presence in the evening twilight ..\\n\\n-- \\n* Fred Baube (tm)\\n',\n",
       "       'From: nsmca@aurora.alaska.edu\\nSubject: Space Design Movies?\\nArticle-I.D.: aurora.1993Apr23.124722.1\\nOrganization: University of Alaska Fairbanks\\nLines: 11\\nNntp-Posting-Host: acad3.alaska.edu\\n\\nIs there a few Grasp pictures of space related items, namely Space Station\\nDesigns, so you can see the \"finished\" revolt around..\\n\\nIf you don\\'t know what a grasp prograsm is.. Check out some adult entertainment\\nfiles and see what I mean.. Or maybe geta few GIF files and create a \"slide\\nshows\" (I think Cshow can do this).. \\n\\nI liek to be able to see a space shuttle design in a AutoCAD program or to see\\nit revolt around and look at it.\\n==\\nMichael Adams, nsmca@acad3.alaska.edu -- I\\'m not high, just jacked\\n',\n",
       "       'From: c23st@kocrsv01.delcoelect.com (Spiros Triantafyllopoulos)\\nSubject: Re: Space Station radio commercial\\nOrganization: Delco Electronics Corp.\\nLines: 25\\n\\nIn article <C5r2I1.793@skates.gsfc.nasa.gov> xrcjd@resolve.gsfc.nasa.gov (Charles J. Divine) writes:\\n>A brief political/cultural item.\\n>\\n>Radio station WGMS in Washington is a classical music station with\\n>a large audience among high officials (elected and otherwise).  \\n>Imagine a radio station that advertises Mercedes Benzes, diamond\\n>jewelry, expensive resorts and (truthfully) Trident submarines.\\n>\\n>This morning I heard a commercial for the space station project.\\n>Didn\\'t catch the advertiser.\\n>\\n>Guess they\\'re pulling out all the stops.\\n\\nIn the Air Force world at least, the crisis escalates when scale\\nmodels of the plane in question (i.e. about to be sacrificed) begin to\\narrive in key Senators and Congresspersons\\' offices.\\n\\nOf course it is assumed that coffee mugs and other decorative junk has\\nbeen tried earlier.\\n\\nSpiros\\n-- \\nSpiros Triantafyllopoulos                    c23st@kocrsv01.delcoelect.com\\nSoftware Technology, Delco Electronics       (317) 451-0815\\nGM Hughes Electronics, Kokomo, IN 46904      \"I post, therefore I ARMM\"\\n',\n",
       "       'From: pgf@srl03.cacs.usl.edu (Phil G. Fraering)\\nSubject: Re: Griffin / Office of Exploration: RIP\\nOrganization: Univ. of Southwestern Louisiana\\nLines: 43\\n\\nyamauchi@ces.cwru.edu (Brian Yamauchi) writes:\\n\\n>Any comments on the absorbtion of the Office of Exploration into the\\n>Office of Space Sciences and the reassignment of Griffin to the \"Chief\\n>Engineer\" position?  Is this just a meaningless administrative\\n>shuffle, or does this bode ill for SEI?\\n\\n>In my opinion, this seems like a Bad Thing, at least on the surface.\\n>Griffin seemed to be someone who was actually interested in getting\\n>things done, and who was willing to look an innovative approaches to\\n>getting things done faster, better, and cheaper.  It\\'s unclear to me\\n>whether he will be able to do this at his new position.\\n\\n>Does anyone know what his new duties will be?\\n\\nFirst I\\'ve heard of it. Offhand:\\n\\nGriffin is no longer an \"office\" head, so that\\'s bad.\\n\\nOn the other hand:\\n\\nRegress seemed to think: we can\\'t fund anything by Griffin, because\\nthat would mean (and we have the lies by the old hardliners about the\\n$ 400 billion mars mission to prove it) that we would be buying into a\\nmission to Mars that would cost 400 billion. Therefore there will be\\nno Artemis or 20 million dollar lunar orbiter et cetera...\\n\\nThey were killing Griffin\\'s main program simply because some sycophants\\nsomewhere had Congress beleivin that to do so would simply be to buy into\\nthe same old stuff. Sorta like not giving aid to Yeltsin because he\\'s\\na communist hardliner.\\n\\nAt least now the sort of reforms Griffin was trying to bring forward\\nwon\\'t be trapped in their own little easily contained and defunded\\nghetto. That Griffin is staying in some capacity is very very very\\ngood. And if he brings something up, noone can say \"why don\\'t you go\\nback to the OSE where you belong\" (and where he couldn\\'t even get money\\nfor design studies).\\n--\\nPhil Fraering         |\"Seems like every day we find out all sorts of stuff.\\npgf@srl02.cacs.usl.edu|Like how the ancient Mayans had televison.\" Repo Man\\n\\n\\n',\n",
       "       'From: nsmca@aurora.alaska.edu\\nSubject: Re: Why not give $1 billion to first year-long moon residents?\\nArticle-I.D.: aurora.1993Apr19.130922.1\\nOrganization: University of Alaska Fairbanks\\nLines: 28\\nNntp-Posting-Host: acad3.alaska.edu\\n\\nIn article <1993Apr19.144427.17399@aio.jsc.nasa.gov>, kjenks@gothamcity.jsc.nasa.gov writes:\\n> Gene Wright (gene@theporch.raider.net) wrote:\\n> : Announce that a reward of $1 billion would go to the first corporation \\n> : who successfully keeps at least 1 person alive on the moon for a year. \\n> : Then you\\'d see some of the inexpensive but not popular technologies begin \\n> : to be developed. THere\\'d be a different kind of space race then!\\n> \\n> I\\'m an advocate of this idea for funding Space Station work, and I\\n> throw around the $1 billion figure for that \"reward.\"  I suggest that\\n> you increase the Lunar reward to about $3 billion.\\n> \\n> This would encourage private industry to invest in space, which \\n> should be one of NASA\\'s primary goals.\\n> \\n> -- Ken Jenks, NASA/JSC/GM2, Space Shuttle Program Office\\n>       kjenks@gothamcity.jsc.nasa.gov  (713) 483-4368\\n> \\n>      \"Better.  Faster.  Cheaper.\" -- Daniel S. Goldin, NASA Administrator\\n\\n\\nAlso would maybe get the Russians Involved. After all they do have the resources\\nto do it in part.. But they need the capital and the goal..\\n\\nI wonder if renting the russians resources would be a disqualification?\\n\\n\\n==\\nMichael Adams, nsmca@acad3.alaska.edu -- I\\'m not high, just jacked\\n',\n",
       "       'From: ralph.buttigieg@f635.n713.z3.fido.zeta.org.au (Ralph Buttigieg)\\nSubject: Commercial point of view\\nOrganization: Fidonet. Gate admin is fido@socs.uts.edu.au\\nLines: 29\\n\\nOriginal to: szabo@techbook.com\\nG\\'day szabo@techbook.com\\n\\n29 Mar 93 07:28, szabo@techbook.com wrote to All:\\n\\n sc> szabo@techbook.com (Nick Szabo), via Kralizec 3:713/602\\n\\n sc> Here are some longer-term markets to consider:\\n\\nHere are some more:\\n\\n* Terrestrial illumination from orbiting mirrors.\\n\\n* World enviroment and disaster monitering system. (the Japanese have\\nalready developed a plan for this, called WEDOS) Although this may be more\\nof a \"public good\".\\n\\n* Space tourism.\\n\\n* Energy relay satellites\\n\\nta\\n\\nRalph\\n\\n--- GoldED 2.41\\n * Origin: VULCAN\\'S WORLD - Sydney Australia (02) 635-6797  3:713/6\\n(3:713/635)\\n\\n',\n",
       "       \"From: clj@ksr.com (Chris Jones)\\nSubject: Re: Proton/Centaur?\\nReply-To: clj@ksr.com (Chris Jones)\\nOrganization: Kendall Square Research Corp\\nLines: 20\\nIn-reply-to: prb@access.digex.com (Pat)\\n\\nIn article <1r2aii$ivs@access.digex.net>, prb@access (Pat) writes:\\n>In article <1993Apr20.211638.168730@zeus.calpoly.edu> jgreen@trumpet.calpoly.edu (James Thomas Green) writes:\\n>>Has anyone looked into the possiblity of a Proton/Centaur combo?\\n>\\n>I don't know a whole lot on Proton, but given that it is a multi stage\\n>rocket,  up to 4 stages, it may not really need the Centaur,  plus\\n>it may end up seriously beating on said centaur.   \\n\\nThe Proton has been used in 2, 3, and 4 stage versions.  The two stage version\\nwas used for the first 3 launches, while the 3 and 4 stage versions are used\\ntoday.  The four stage version is used mostly for escape (and geosynchronous?)\\norbits, while the 3 stage version is used for low earth orbits.  Since this is\\nthe version that launched Mir and the Salyuts (and the add-on modules for Mir),\\nas long as Centaur is smaller than Mir (which I believe it is), it should fit\\nunder the shroud.\\n\\nI vaguely recall that the Russians are developing a LH2/LOX upper stage for the\\nProton.\\n--\\nChris Jones    clj@ksr.com\\n\",\n",
       "       'From: dfegan@lescsse.jsc.nasa.gov (Doug Egan)\\nSubject: Re: *** HELP I NEED SOME ADDRESSES ***\\nOrganization: LESC\\nLines: 19\\n\\nIn <1993Apr20.041300.21721@ncsu.edu> jmcocker@eos.ncsu.edu (Mitch) writes:\\n\\n>    I\\'m trying to get mailing addresses for the following\\n>companies.  Specifically, I need addresses for their personnel\\n>offices or like bureau.  The companies are:\\n\\n>\\t- Space Industries, Inc.  (Somewhere in Houston)\\n          101 Courageous Dr. \\n          Leage City, TX  77573\\n          Phone: (713) 538-6000   \\n\\n         \\nGood Luck!\\nDoug \\n--\\n Doug Egan                                  \"It\\'s not what you got -\\n Lockheed Engineering and Sciences Co.       It\\'s what you give.\"          \\n Houston, TX                                                  -Tesla      \\n ***** email:  egan@blkbox.com  *****                                    \\n',\n",
       "       'From: khayash@hsc.usc.edu (Ken Hayashida)\\nSubject: Re: Life on Mars???\\nOrganization: University of Southern California, Los Angeles, CA\\nLines: 25\\nNNTP-Posting-Host: hsc.usc.edu\\n\\nIn article <1993Apr26.184507.10511@aio.jsc.nasa.gov> kjenks@gothamcity.jsc.nasa.gov writes:\\n>I know it\\'s only wishful thinking, with our current President,\\n>but this is from last fall:\\n>\\n>     \"Is there life on Mars?  Maybe not now.  But there will be.\"\\n>        -- Daniel S. Goldin, NASA Administrator, 24 August 1992\\n>\\n>-- Ken Jenks, NASA/JSC/GM2, Space Shuttle Program Office\\n>      kjenks@gothamcity.jsc.nasa.gov  (713) 483-4368\\n\\nLets hear it for Dan Goldin...now if he can only convince the rest of\\nour federal government that the space program is a worth while\\ninvestment!\\n\\nI hope that I will live to see the day we walk on Mars, but\\nwe need to address the technical hurdles first!  If there\\'s sufficient\\ninterest, maybe we should consider starting a sci.space group \\ndevoted to the technical analysis of long-duration human spaceflight.\\nMost of you regulars know that I\\'m interested in starting this analysis\\nas soon as possible.\\n\\nKen\\nkhayash@hsc.usc.edu\\nUSC School of Medicine, Class of 1994\\n\\n',\n",
       "       'From: mccall@mksol.dseg.ti.com (fred j mccall 575-3539)\\nSubject: Re: PLANETS STILL: IMAGES ORBIT BY ETHER TWIST\\nArticle-I.D.: mksol.1993Apr22.213815.12288\\nOrganization: Texas Instruments Inc\\nLines: 22\\n\\nIn <1993Apr22.130923.115397@zeus.calpoly.edu> dmcaloon@tuba.calpoly.edu (David McAloon) writes:\\n\\n> ETHER IMPLODES 2 EARTH CORE, IS GRAVITY!!!\\n\\nIf not for the lack of extraneously capitalized words, I\\'d swear that\\nMcElwaine had changed his name and moved to Cal Poly.  I also find the\\nchoice of newsgroups \\'interesting\\'.  Perhaps someone should tell this\\nguy that \\'sci.astro\\' doesn\\'t stand for \\'astrology\\'?\\n\\nIt\\'s truly frightening that posts like this are originating at what\\nare ostensibly centers of higher learning in this country.  Small\\nwonder that the rest of the world thinks we\\'re all nuts and that we\\nhave the problems that we do.\\n\\n[In case you haven\\'t gotten it yet, David, I don\\'t think this was\\nquite appropriate for a posting to \\'sci\\' groups.]\\n\\n-- \\n\"Insisting on perfect safety is for people who don\\'t have the balls to live\\n in the real world.\"   -- Mary Shafer, NASA Ames Dryden\\n------------------------------------------------------------------------------\\nFred.McCall@dseg.ti.com - I don\\'t speak for others and they don\\'t speak for me.\\n'],\n",
       "      dtype='<U40353')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CxBYzBs1o5N"
   },
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Code your own TF-IDF representation function and use it on this dataset. (Don't use code from libraries. Build your own function with Numpy/Pandas). Use the formular TFIDF = TF * (IDF+1). The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. The term frequency is the raw count of a term in a document. The inverse document frequency is the natural logarithm of the inverse fraction of the documents that contain the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02</th>\n",
       "      <th>041300</th>\n",
       "      <th>07</th>\n",
       "      <th>0815</th>\n",
       "      <th>10</th>\n",
       "      <th>101</th>\n",
       "      <th>10511</th>\n",
       "      <th>11</th>\n",
       "      <th>115397</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yeltsin</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>z3</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zeus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    02  041300  07  0815  10  101  10511  11  115397  12  ...  yellow  \\\n",
       "0    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "1    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "2    0       0   0     0   0    0      0   1       0   0  ...       0   \n",
       "3    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "4    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "5    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "6    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "7    0       0   0     0   1    0      0   0       0   0  ...       0   \n",
       "8    0       0   0     0   0    0      0   0       0   0  ...       3   \n",
       "9    0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "10   0       0   0     0   0    0      0   0       0   1  ...       0   \n",
       "11   0       0   0     0   0    0      0   1       0   0  ...       0   \n",
       "12   0       0   0     1   0    0      0   0       0   0  ...       0   \n",
       "13   0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "14   0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "15   1       0   1     0   0    0      0   0       0   0  ...       0   \n",
       "16   0       0   0     0   0    0      0   0       0   0  ...       0   \n",
       "17   0       1   0     0   0    1      0   0       0   0  ...       0   \n",
       "18   0       0   0     0   0    0      1   0       0   0  ...       0   \n",
       "19   0       0   0     0   0    0      0   0       1   0  ...       0   \n",
       "\n",
       "    yeltsin  yet  you  young  younger  your  z3  zeta  zeus  \n",
       "0         0    0    0      0        0     0   0     0     0  \n",
       "1         0    0    0      0        1     0   0     0     0  \n",
       "2         0    0    0      1        0     0   0     0     0  \n",
       "3         0    0    5      0        0     2   0     0     0  \n",
       "4         0    0    0      0        0     0   0     0     0  \n",
       "5         0    0    0      0        0     0   0     0     0  \n",
       "6         0    0    0      0        0     0   0     0     0  \n",
       "7         0    0    1      1        0     0   0     0     0  \n",
       "8         0    0    1      0        0     0   0     0     0  \n",
       "9         0    0    0      0        0     0   0     0     0  \n",
       "10        0    0    0      0        0     0   0     0     0  \n",
       "11        0    0    2      0        0     0   0     0     0  \n",
       "12        0    0    0      0        0     0   0     0     0  \n",
       "13        1    0    2      0        0     0   0     0     0  \n",
       "14        0    0    2      0        0     0   0     0     0  \n",
       "15        0    0    0      0        0     0   1     1     0  \n",
       "16        0    0    0      0        0     0   0     0     1  \n",
       "17        0    0    2      0        0     0   0     0     0  \n",
       "18        0    0    1      0        0     0   0     0     0  \n",
       "19        0    1    1      0        0     0   0     0     1  \n",
       "\n",
       "[20 rows x 1440 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvec = CountVectorizer()\n",
    "df = pd.DataFrame(countvec.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: calculating tf does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df):\n",
    "    # term frequency\n",
    "    term_count = df.sum(axis=1)\n",
    "    term_count = df.sum(axis=1)\n",
    "    tf = df.div(term_count, axis = 0)\n",
    "    \n",
    "    # number of documents that contain term\n",
    "    doc_num_contains = df[df > 0].count()\n",
    "    \n",
    "    # total number of documents in data set\n",
    "    doc_count = df.shape[0]\n",
    "    \n",
    "    # idf following formula from class \n",
    "    idf = np.log(doc_count/doc_num_contains)\n",
    "          \n",
    "    tfidf = tf * (idf + 1)\n",
    "    \n",
    "    return(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: calculation with initial df works?\n",
    ".fit_transform initialises df with tf so a seperate calculation is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df):\n",
    "    \n",
    "    # number of documents that contain term\n",
    "    doc_num_contains = df[df > 0].count()\n",
    "    \n",
    "    # total number of documents in data set\n",
    "    doc_count = df.shape[0]\n",
    "    \n",
    "    # idf following formula from class \n",
    "    idf = np.log(doc_count/doc_num_contains)\n",
    "          \n",
    "    tfidf = df * (idf + 1)\n",
    "    \n",
    "    return(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "LAQX0zw11o5N",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this implementation correct?\n",
      "Answer: Yes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvec = CountVectorizer()\n",
    "df = pd.DataFrame(countvec.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
    "# row = instance\n",
    "    \n",
    "rep = tfidf(df)\n",
    "\n",
    "# Check if your implementation is correct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False, use_idf=True)\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
    "answer=['No','Yes']\n",
    "epsilon = 0.0001\n",
    "if rep is None: \n",
    "  print (f'Is this implementation correct?\\nAnswer: {answer[0]}')\n",
    "if rep is not None:\n",
    "  print (f'Is this implementation correct?\\nAnswer: {answer[1*np.all((X_train - rep) < epsilon)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tfidf(df):\n",
    "#    \n",
    "#    tf = df.sum()\n",
    "#    \n",
    "#    denomIdf = df[df > 0].count()\n",
    "#    \n",
    "#    totDocs = df.shape[0]\n",
    "#    \n",
    "#    idf = np.log(totDocs/denomIdf)\n",
    "#    \n",
    "#    test = df.where(df < 1, 1)\n",
    "#        \n",
    "#    return(df * (test * (idf +1)))\n",
    "#    \n",
    "#tfidf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "yvgshAez8XY2"
   },
   "outputs": [],
   "source": [
    "# an example of what to do with these similarities:\n",
    "\n",
    "\n",
    "# analysis with tf-idf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similiarities = cosine_similarity(rep, rep) # measure of the similarity of the direction of two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity calculates angle between two vectors \n",
    "coliniar - cosine similarity of 0 ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "39RjLr9J8b8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3182784779118088"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(similiarities, 0)\n",
    "max_ind = np.unravel_index(similiarities.argmax(), similiarities.shape)\n",
    "similiarities[max_ind] # highest similarity of two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Problem_Analysis_and_Data_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
